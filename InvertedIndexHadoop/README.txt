The application example we discuss here shows how Hadoop MapReduce can be
exploited for creating an inverted index for a large set of Web documents. An
inverted index contains a set of words (index terms), and for each word it specifies the IDs of all the documents that contain it and the number of occurrences in each document. The inverted index data structure is a central component of a search engine indexing system.

The Mapper (or MapTask) parses text lines coming from some input documents
and emits a pair <word:documentID, numberOfOccurrences> for each word they
contain, where documentID is the identifier of the document and numberOfOccurences is set to 1. Each word is processed with common steps of Natural Language Processing (NLP), such as punctuation removal, lemmatization, and stemming. In order to handle Objects' serialization in a lighter way, programmers have to use specific types for keys and values. As an example, Hadoop uses Text and IntWritable instead of String and Integer, respectively, which contain the
same information by using a much easier abstraction on top of byte arrays.

After word mapping, a combine function is exploited to aggregate intermediate
data produced by mappers, before passing them to reducers. The combiner sums all the occurrences of each word that appear multiple times in a document, and emits a pair (documentID, sumNumberOfOccurrences).

For each word, the Reducer produces the list of all the documents containing that
word and the number of occurrences in each document. Specifically, <word, documentID:numberOfOccurrences> pair is emitted for each word. The set of all output pairs generated by the reduce function forms the inverted index for the input documents.

Finally, a programmer must specify the classes to be used as mapper, combiner, and reducer, the input/output format for such classes, and the data input/output paths in the job.